{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from haralyzer import HarParser, HarPage\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# filename = input('Enter the name of the file: ')\n",
    "# in the HAR Files folder, get the names of all the files\n",
    "files = os.listdir('./HAR Files')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_schedules(data,filename):\n",
    "    classDF = pd.DataFrame(columns=['Class Name','Unique', 'Day + Hour', 'Room', 'Instruction Mode', 'Instructor','Status', 'Flags', 'Core'])\n",
    "\n",
    "    for i in range (len(data['entries'])):\n",
    "        html_content = data['entries'][i]['response']['content']['text']\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        tables = soup.find_all('table')\n",
    "        for table in tables:\n",
    "            class_name = ''\n",
    "            # Find all the rows in the current table\n",
    "            rows = table.find_all('tr')\n",
    "            \n",
    "            # Iterate through the rows\n",
    "            for i,row in enumerate(rows):\n",
    "                # Find all the cells in the current row\n",
    "                # print(row, '\\n')\n",
    "                cells = row.find_all(['th','td'])\n",
    "\n",
    "                \n",
    "                # Process and print cell data\n",
    "                header = False\n",
    "                rowList = []\n",
    "                days =[]\n",
    "                hours = []\n",
    "                for j,cell in enumerate(cells):\n",
    "                    if 'course_header' in cell.get('class', []):\n",
    "                        \n",
    "                        class_name = cell.get_text()\n",
    "                        \n",
    "                        header = True\n",
    "                    else:\n",
    "                        if(j == 1 or j == 2):\n",
    "                            spans = cell.find_all('span')\n",
    "                            \n",
    "                            # print(spans)\n",
    "\n",
    "\n",
    "                            # check if \n",
    "\n",
    "                            for i in range(len(spans)):\n",
    "                                if j == 1:\n",
    "                                    days.append(spans[i].get_text())\n",
    "                                else:\n",
    "                                    hours.append(spans[i].get_text())\n",
    "                        # print(key)\n",
    "\n",
    "                        else:\n",
    "                            value = cell.get_text(strip=True)\n",
    "\n",
    "                            rowList.append(value)\n",
    "\n",
    "                        # if we detect a header, we don't want to print a row\n",
    "                \n",
    "                \n",
    "                \n",
    "                if header == False and i>0:\n",
    "                    # print(class_name)\n",
    "                    rowList.insert(0, class_name)\n",
    "                    if(len(days)!= len(hours)):\n",
    "                        print(len(days),len(hours))\n",
    "                        print('days', days)\n",
    "                        print('hours', hours)\n",
    "                    rowList.insert(2, tuple(zip(tuple(days), tuple(hours))))\n",
    "\n",
    "                    classDF.loc[len(classDF)] =  rowList\n",
    "                    rowList = []\n",
    "            \n",
    "\n",
    "                    \n",
    "\n",
    "                    # check the ending if cropping data!!!\n",
    "                    \n",
    "                    # classDF.loc[len(classDF)] =  classifications\n",
    "                    \n",
    "            # print(days, hours)\n",
    "\n",
    "    classDF['Day + Hour'].apply(tuple)\n",
    "    classDF.drop_duplicates(inplace=True)\n",
    "    classDF.to_csv(f'./CSVs/{filename}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TWTh.har\n",
      "MTWTh.har\n",
      "MTh.har\n",
      "MWF.har\n",
      "TTh.har\n",
      "TThF.har\n",
      ".DS_Store\n",
      "ThF.har\n",
      "Th.har\n",
      "S.har\n",
      "F.har\n",
      "WF.har\n",
      "WTh.har\n",
      "T.har\n",
      "W.har\n",
      "TW.har\n",
      "MT.har\n",
      "M.har\n",
      "MWTh.har\n",
      "MW.har\n",
      "TF.har\n",
      "MTWThF.har\n",
      "ThFS.har\n",
      "MF.har\n",
      "MTW.har\n",
      "FS.har\n",
      "MTTh.har\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    print(file)\n",
    "    if file == '.DS_Store':\n",
    "        continue\n",
    "    with open(f'./HAR Files/{file}', 'r') as f: \n",
    "        har_parser = HarParser(json.loads(f.read()))\n",
    "    data = har_parser.har_data\n",
    "    get_schedules(data,file[:-4])\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MTTh'"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through each <tr>. Assign the first course-header class to the current course name\n",
    "# check if the next <tr> is a course-header class. If so, assign it to the current course name\n",
    "# if not, then convert the <tr> to a row in the table, and add the course name to that row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through every csv in the csvs folder, adn combine them into one csv\n",
    "import glob\n",
    "import pandas as pd\n",
    "df = pd.concat(map(pd.read_csv, glob.glob('csvs/*.csv'))).drop_duplicates()\n",
    "df.to_csv('Ut Course Catalog.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
